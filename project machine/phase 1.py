import pandas as pd
import numpy as np

# ============================================================
# ğŸ“‚ WEEK 1: DATA EXPLORATION
# ============================================================

print("~"*70)
print("ğŸ“˜ WEEK 1: Data Exploration")
print("="*70)

# Read Data - Ù†Ù‚Ø±Ø£ Ø§Ù„Ù…Ù„Ù Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·
print("\nğŸ“¥ Reading Dataset...\n")
# ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù ØµØ­ÙŠØ­
health_df = pd.read_csv("Enhanced_Vitamin_D_Deficiency_Prediction.csv") 
copy_df = health_df.copy()

# Show random sample
print("\nğŸ² Random Sample from the Dataset:\n")
print(copy_df.sample(5))

# Size Of Data
print("\nğŸ“ Size of the Dataset:\n")
print(f"Shape: {copy_df.shape}")

# Info About Data
print("\nâ„¹ï¸ Information about the Dataset:\n")
copy_df.info()

#Head of colØ¹mns
print("\n1ï¸âƒ£ Columns name:\n")
print(copy_df.columns)


# Describe Data
print("\nğŸ“Š Descriptive Statistics:\n")
print(copy_df.describe())

# Unique Values
print("\nğŸ”¢ Number of Unique Values in the Dataset:\n")
print(copy_df.nunique())


target_col = 'Deficiency_Status'

print(f"\nâš–ï¸ Balance of Target Column ({target_col}):\n")
print(copy_df[target_col].value_counts())

print(f"\nâš–ï¸ğŸ’¯ Balance of Target Column ({target_col}) (%%):\n")
print(copy_df[target_col].value_counts(normalize=True) * 100)


# ============================================================
# ğŸ§¹ WEEK 2: DATA CLEANING & HANDLING
# ============================================================

print("\n" + "="*70)
print("ğŸ§¹ WEEK 2: Data Cleaning & Handling")
print("="*70)

# --- 1ï¸âƒ£ Check Missing Values ---
print("\n--- 1ï¸âƒ£ Checking for Missing Values ---\n")
print(copy_df.isnull().sum())

# Optionally fill missing values
copy_df.fillna(copy_df.median(numeric_only=True), inplace=True)
print("\nâœ… Missing values imputed with median (numeric columns only).\n")

# --- 2ï¸âƒ£ Drop Duplicate Rows ---
print("\n--- 2ï¸âƒ£ Checking and Removing Duplicate Rows ---\n")
print("Duplicates before removal:", copy_df.duplicated().sum())
copy_df.drop_duplicates(inplace=True)
print("âœ… Duplicate rows removed.\n")

# --- 3ï¸âƒ£ Outlier Detection ---
print("\n--- 3ï¸âƒ£ Detecting Outliers using IQR Method ---\n")

# Select only numeric columns for outlier detection
numeric_cols_df = copy_df.select_dtypes(include=[np.number])
Q1_detect = numeric_cols_df.quantile(0.25)
Q3_detect = numeric_cols_df.quantile(0.75)
IQR_detect = Q3_detect - Q1_detect
outliers = ((numeric_cols_df < (Q1_detect - 1.5 * IQR_detect)) | (numeric_cols_df > (Q3_detect + 1.5 * IQR_detect))).sum()
print("Outliers per column (before handling):\n", outliers)


# --- 4ï¸âƒ£ Outlier Handling (Sequential Dropping like the image) ---
print("\n--- 4ï¸âƒ£ Outlier Handling (Sequential Dropping) ---\n")


numeric_cols_list = copy_df.select_dtypes(include=[np.number]).columns

shape_before_drop = copy_df.shape
print(f"Shape before dropping outliers: {shape_before_drop}")


for col in numeric_cols_list:
   
    Q1 = copy_df[col].quantile(0.25)
    Q3 = copy_df[col].quantile(0.75)
    IQR = Q3 - Q1
    
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
  
    rows_before = copy_df.shape[0]
    
    
    copy_df = copy_df[(copy_df[col] >= lower_bound) & (copy_df[col] <= upper_bound)]
    
    
    rows_after = copy_df.shape[0]
    print(f"  - Processed '{col}': Removed {rows_before - rows_after} rows.")

shape_after_drop = copy_df.shape
print("\nâœ… Sequential outlier dropping completed.")
print(f"Final shape after dropping outliers: {shape_after_drop}")
print(f"Total rows removed: {shape_before_drop[0] - shape_after_drop[0]}\n")


print("\nâœ… Week 2 Data Cleaning & Handling Completed Successfully!\n")

# ============================================================
# ğŸš€ END OF WEEK 2
# ============================================================

print("="*70)
print("ğŸ‰ Data Exploration & Cleaning Done! Ready for Week 3 ğŸš€")
print("="*70)